{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddb7b41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Loading raw housing data...\n",
      "Loading random 1,000,000 records from 22,489,348 total...\n",
      "âœ… Loaded 1,000,000 records\n",
      "Columns: ['Transaction unique identifier', 'Price', 'Date of Transfer', 'Property Type', 'Old/New', 'Duration', 'Town/City', 'District', 'County', 'PPDCategory Type', 'Record Status - monthly file only']\n",
      "\n",
      "ðŸ”§ Renaming columns...\n",
      "âœ… Columns renamed\n",
      "\n",
      "ðŸ”§ Converting data types...\n",
      "âœ… Loaded 1,000,000 records\n",
      "Columns: ['Transaction unique identifier', 'Price', 'Date of Transfer', 'Property Type', 'Old/New', 'Duration', 'Town/City', 'District', 'County', 'PPDCategory Type', 'Record Status - monthly file only']\n",
      "\n",
      "ðŸ”§ Renaming columns...\n",
      "âœ… Columns renamed\n",
      "\n",
      "ðŸ”§ Converting data types...\n",
      "âœ… Date features created\n",
      "\n",
      "ðŸ”§ Creating categorical labels...\n",
      "âœ… Labels created\n",
      "\n",
      "ðŸ”§ Cleaning text fields...\n",
      "âœ… Date features created\n",
      "\n",
      "ðŸ”§ Creating categorical labels...\n",
      "âœ… Labels created\n",
      "\n",
      "ðŸ”§ Cleaning text fields...\n",
      "âœ… Text fields cleaned\n",
      "\n",
      "ðŸ” Cleaning basic issues...\n",
      "âœ… Text fields cleaned\n",
      "\n",
      "ðŸ” Cleaning basic issues...\n",
      "âœ… Removed 0 rows with non-positive price\n",
      "âœ… No remaining missing values (after our cleaning)\n",
      "\n",
      "ðŸ”§ Dropping unnecessary / duplicate columns...\n",
      "âœ… Removed 0 rows with non-positive price\n",
      "âœ… No remaining missing values (after our cleaning)\n",
      "\n",
      "ðŸ”§ Dropping unnecessary / duplicate columns...\n",
      "âœ… Unnecessary columns removed\n",
      "Removed 1,304 rows below Â£10k\n",
      "\n",
      "ðŸ”§ Removing outliers using 3-sigma rule...\n",
      "  Mean: Â£178,012\n",
      "  Std Dev: Â£380,242\n",
      "  Lower bound: Â£0\n",
      "  Upper bound: Â£1,318,739\n",
      "  Original records: 998,696\n",
      "  After filtering: 994,714\n",
      "  Removed: 3,982 extreme outliers\n",
      "\n",
      "ðŸ“Š FINAL CLEAN DATASET SUMMARY:\n",
      "==================================================\n",
      "Total records: 994,714\n",
      "Columns: 11\n",
      "Years: 1995 - 2017\n",
      "Price range: Â£10,000 - Â£1,318,000\n",
      "\n",
      "Columns:\n",
      "['price', 'town_city', 'district', 'county', 'year', 'month', 'quarter', 'day_of_week', 'property_type_label', 'is_new_build', 'tenure_label']\n",
      "\n",
      "ðŸ’¾ Saving clean data...\n",
      "âœ… Unnecessary columns removed\n",
      "Removed 1,304 rows below Â£10k\n",
      "\n",
      "ðŸ”§ Removing outliers using 3-sigma rule...\n",
      "  Mean: Â£178,012\n",
      "  Std Dev: Â£380,242\n",
      "  Lower bound: Â£0\n",
      "  Upper bound: Â£1,318,739\n",
      "  Original records: 998,696\n",
      "  After filtering: 994,714\n",
      "  Removed: 3,982 extreme outliers\n",
      "\n",
      "ðŸ“Š FINAL CLEAN DATASET SUMMARY:\n",
      "==================================================\n",
      "Total records: 994,714\n",
      "Columns: 11\n",
      "Years: 1995 - 2017\n",
      "Price range: Â£10,000 - Â£1,318,000\n",
      "\n",
      "Columns:\n",
      "['price', 'town_city', 'district', 'county', 'year', 'month', 'quarter', 'day_of_week', 'property_type_label', 'is_new_build', 'tenure_label']\n",
      "\n",
      "ðŸ’¾ Saving clean data...\n",
      "âœ… Saved to data/cleaned/housing_clean.parquet\n",
      "File size: 6.8 MB\n",
      "\n",
      "ðŸŽ‰ CLEANING COMPLETE!\n",
      "\n",
      "ðŸ’¡ This file can now be used by the housing deployment:\n",
      "   - housing-deployment/frontend will use it for dropdown options\n",
      "   - Location: /Users/hamidiqbal/Documents/ThomasMore/ML/cloud/data1_data2/cloud_ai_project-main/data/cleaned/housing_clean.parquet\n",
      "âœ… Saved to data/cleaned/housing_clean.parquet\n",
      "File size: 6.8 MB\n",
      "\n",
      "ðŸŽ‰ CLEANING COMPLETE!\n",
      "\n",
      "ðŸ’¡ This file can now be used by the housing deployment:\n",
      "   - housing-deployment/frontend will use it for dropdown options\n",
      "   - Location: /Users/hamidiqbal/Documents/ThomasMore/ML/cloud/data1_data2/cloud_ai_project-main/data/cleaned/housing_clean.parquet\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Housing Data - Final Cleaning Pipeline\n",
    "# ==========================================\n",
    "# This notebook takes raw data and produces clean, modeling-ready data\n",
    "# Team members: Hamid Iqbal, Ibrahim Afkir\n",
    "# What this does: Loads raw CSV, cleans columns, creates features, saves clean data\n",
    "# ==========================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# ==========================================\n",
    "# 1. Load Raw Data (1M random sample, reproducible)\n",
    "# ==========================================\n",
    "print(\"ðŸ“‚ Loading raw housing data...\")\n",
    "csv_path = Path(\"Dataset_1_UK_housing/price_paid_records.csv\")\n",
    "\n",
    "total_rows = 22_489_348\n",
    "sample_size = 1_000_000\n",
    "\n",
    "np.random.seed(42)  # âœ… reproducible sampling\n",
    "\n",
    "print(f\"Loading random {sample_size:,} records from {total_rows:,} total...\")\n",
    "skip = sorted(np.random.choice(range(1, total_rows), total_rows - sample_size, replace=False))\n",
    "df_raw = pd.read_csv(csv_path, skiprows=skip)\n",
    "\n",
    "print(f\"âœ… Loaded {len(df_raw):,} records\")\n",
    "print(f\"Columns: {df_raw.columns.tolist()}\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. Rename Columns\n",
    "# ==========================================\n",
    "print(\"\\nðŸ”§ Renaming columns...\")\n",
    "\n",
    "column_mapping = {\n",
    "    \"Transaction unique identifier\": \"transaction_id\",\n",
    "    \"Price\": \"price\",\n",
    "    \"Date of Transfer\": \"transfer_date\",\n",
    "    \"Property Type\": \"property_type\",\n",
    "    \"Old/New\": \"is_new\",\n",
    "    \"Duration\": \"tenure_type\",\n",
    "    \"Town/City\": \"town_city\",\n",
    "    \"District\": \"district\",\n",
    "    \"County\": \"county\",\n",
    "    \"PPDCategory Type\": \"ppd_category\",\n",
    "    \"Record Status - monthly file only\": \"record_status\",\n",
    "    \"Postcode\": \"postcode\",\n",
    "    \"PAON\": \"paon\",\n",
    "    \"SAON\": \"saon\",\n",
    "    \"Street\": \"street\",\n",
    "    \"Locality\": \"locality\",\n",
    "}\n",
    "\n",
    "df = df_raw.rename(columns=column_mapping)\n",
    "print(\"âœ… Columns renamed\")\n",
    "\n",
    "# ==========================================\n",
    "# 3. Fix Data Types & Date Features\n",
    "# ==========================================\n",
    "print(\"\\nðŸ”§ Converting data types...\")\n",
    "\n",
    "df[\"transfer_date\"] = pd.to_datetime(df[\"transfer_date\"])\n",
    "\n",
    "df[\"year\"] = df[\"transfer_date\"].dt.year\n",
    "df[\"month\"] = df[\"transfer_date\"].dt.month\n",
    "df[\"quarter\"] = df[\"transfer_date\"].dt.quarter\n",
    "df[\"day_of_week\"] = df[\"transfer_date\"].dt.dayofweek\n",
    "\n",
    "print(\"âœ… Date features created\")\n",
    "\n",
    "# ==========================================\n",
    "# 4. Create Label Columns\n",
    "# ==========================================\n",
    "print(\"\\nðŸ”§ Creating categorical labels...\")\n",
    "\n",
    "property_type_mapping = {\n",
    "    \"D\": \"Detached\",\n",
    "    \"S\": \"Semi-Detached\",\n",
    "    \"T\": \"Terraced\",\n",
    "    \"F\": \"Flat\",\n",
    "    \"O\": \"Other\",\n",
    "}\n",
    "df[\"property_type_label\"] = df[\"property_type\"].map(property_type_mapping)\n",
    "\n",
    "df[\"is_new_build\"] = df[\"is_new\"] == \"Y\"\n",
    "\n",
    "df[\"tenure_label\"] = df[\"tenure_type\"].map({\"F\": \"Freehold\", \"L\": \"Leasehold\"})\n",
    "df[\"tenure_label\"] = df[\"tenure_label\"].fillna(\"Unknown\")\n",
    "\n",
    "print(\"âœ… Labels created\")\n",
    "\n",
    "# ==========================================\n",
    "# 5. Clean Text Fields\n",
    "# ==========================================\n",
    "print(\"\\nðŸ”§ Cleaning text fields...\")\n",
    "\n",
    "text_cols = [\"town_city\", \"district\", \"county\", \"postcode\", \"locality\", \"street\"]\n",
    "\n",
    "for col in text_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna(\"UNKNOWN\").astype(str).str.strip().str.upper()\n",
    "\n",
    "print(\"âœ… Text fields cleaned\")\n",
    "\n",
    "# ==========================================\n",
    "# 6. Basic sanity checks (price & missing)\n",
    "# ==========================================\n",
    "print(\"\\nðŸ” Cleaning basic issues...\")\n",
    "\n",
    "# Remove non-positive prices (just in case)\n",
    "before_price = len(df)\n",
    "df = df[df[\"price\"] > 0]\n",
    "print(f\"âœ… Removed {before_price - len(df):,} rows with non-positive price\")\n",
    "\n",
    "# Show remaining missing values\n",
    "missing = df.isna().sum()\n",
    "missing = missing[missing > 0]\n",
    "if len(missing) == 0:\n",
    "    print(\"âœ… No remaining missing values (after our cleaning)\")\n",
    "else:\n",
    "    print(\"âš ï¸ Remaining missing values:\")\n",
    "    print(missing)\n",
    "\n",
    "# ==========================================\n",
    "# 7. Drop columns we don't want for modeling\n",
    "# ==========================================\n",
    "print(\"\\nðŸ”§ Dropping unnecessary / duplicate columns...\")\n",
    "\n",
    "cols_to_drop = [\n",
    "    \"ppd_category\",\n",
    "    \"record_status\",\n",
    "    \"transaction_id\",\n",
    "    \"paon\",\n",
    "    \"saon\",\n",
    "    \"street\",\n",
    "    \"locality\",\n",
    "    \"transfer_date\",      # we keep year/month/quarter/day_of_week instead\n",
    "    \"property_type\",      # keep property_type_label\n",
    "    \"is_new\",             # keep is_new_build\n",
    "    \"tenure_type\",        # keep tenure_label\n",
    "]\n",
    "\n",
    "df = df.drop(columns=[c for c in cols_to_drop if c in df.columns], errors=\"ignore\")\n",
    "\n",
    "print(\"âœ… Unnecessary columns removed\")\n",
    "\n",
    "# Remove unrealistic low prices\n",
    "before_low = len(df)\n",
    "df = df[df[\"price\"] >= 10000]   # keep prices >= Â£10k\n",
    "print(f\"Removed {before_low - len(df):,} rows below Â£10k\")\n",
    "\n",
    "# ==========================================\n",
    "# 8. Remove Extreme Outliers (3-sigma)\n",
    "# ==========================================\n",
    "print(\"\\nðŸ”§ Removing outliers using 3-sigma rule...\")\n",
    "\n",
    "mean_price = df[\"price\"].mean()\n",
    "std_price = df[\"price\"].std()\n",
    "\n",
    "lower_bound = max(0, mean_price - 3 * std_price)\n",
    "upper_bound = mean_price + 3 * std_price\n",
    "\n",
    "print(f\"  Mean: Â£{mean_price:,.0f}\")\n",
    "print(f\"  Std Dev: Â£{std_price:,.0f}\")\n",
    "print(f\"  Lower bound: Â£{lower_bound:,.0f}\")\n",
    "print(f\"  Upper bound: Â£{upper_bound:,.0f}\")\n",
    "\n",
    "before_outliers = len(df)\n",
    "df = df[(df[\"price\"] >= lower_bound) & (df[\"price\"] <= upper_bound)].copy()\n",
    "print(f\"  Original records: {before_outliers:,}\")\n",
    "print(f\"  After filtering: {len(df):,}\")\n",
    "print(f\"  Removed: {before_outliers - len(df):,} extreme outliers\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 9. Final Summary\n",
    "# ==========================================\n",
    "print(\"\\nðŸ“Š FINAL CLEAN DATASET SUMMARY:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total records: {len(df):,}\")\n",
    "print(f\"Columns: {len(df.columns)}\")\n",
    "print(f\"Years: {df['year'].min()} - {df['year'].max()}\")\n",
    "print(f\"Price range: Â£{df['price'].min():,} - Â£{df['price'].max():,}\")\n",
    "print(\"\\nColumns:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# ==========================================\n",
    "# 10. Save Clean Data\n",
    "# ==========================================\n",
    "print(\"\\nðŸ’¾ Saving clean data...\")\n",
    "output_path = Path(\"data/cleaned/housing_clean.parquet\")\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "df.to_parquet(output_path, index=False)\n",
    "print(f\"âœ… Saved to {output_path}\")\n",
    "print(f\"File size: {output_path.stat().st_size / (1024**2):.1f} MB\")\n",
    "\n",
    "print(\"\\nðŸŽ‰ CLEANING COMPLETE!\")\n",
    "print(f\"\\nðŸ’¡ This file can now be used by the housing deployment:\")\n",
    "print(f\"   - housing-deployment/frontend will use it for dropdown options\")\n",
    "print(f\"   - Location: {output_path.absolute()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bf5437",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
